{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31b500b5",
   "metadata": {},
   "source": [
    "# The feedforward neural network model for learning PageRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9854c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8783184",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdc752f",
   "metadata": {},
   "source": [
    "## Loading the dataset from numpy files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a2177fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.98507331e-05])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pageank as the target or label data\n",
    "target_pagerank = np.load(\"fb_co_pages_pageranks.npy\", mmap_mode=None, allow_pickle=False, fix_imports=True, encoding='ASCII')\n",
    "target_pagerank[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23f24350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99850733])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scaling the PageRank data\n",
    "target_pagerank = target_pagerank * 10000\n",
    "target_pagerank[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cec6039f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14113, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_pagerank.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "613797d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the order 5 NFDC matrix as the feature set\n",
    "matrix_1 = np.load(\"fb_co_pages_discounted_NDFC_matrix_r1-30_sta1_max50_rad5.npy\", mmap_mode=None, allow_pickle=False, fix_imports=True, encoding='ASCII')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94c81831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14113, 6, 17)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac052a5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000e+00, 0.00000e+00, 0.00000e+00, 2.00000e+00, 1.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00],\n",
       "       [0.00000e+00, 0.00000e+00, 2.05556e-01, 3.27778e-01, 8.33330e-02,\n",
       "        0.00000e+00, 2.05556e-01, 5.55560e-02, 0.00000e+00, 0.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 1.22222e-01,\n",
       "        0.00000e+00, 0.00000e+00],\n",
       "       [1.91670e-02, 1.25000e-03, 5.37500e-02, 1.47197e-01, 1.47917e-01,\n",
       "        9.60980e-02, 6.51140e-02, 1.86780e-01, 3.08330e-02, 5.54170e-02,\n",
       "        2.45830e-02, 8.75000e-03, 2.04170e-02, 6.15150e-02, 3.15150e-02,\n",
       "        1.81820e-02, 3.15150e-02],\n",
       "       [1.14010e-02, 2.27700e-02, 2.77640e-02, 6.91750e-02, 5.25770e-02,\n",
       "        6.92940e-02, 9.92490e-02, 9.42720e-02, 9.63990e-02, 1.23248e-01,\n",
       "        6.29110e-02, 4.95400e-02, 3.59460e-02, 2.51710e-02, 1.24235e-01,\n",
       "        1.33000e-02, 2.27470e-02],\n",
       "       [2.04820e-02, 2.95600e-02, 3.35690e-02, 7.83390e-02, 7.92010e-02,\n",
       "        1.06807e-01, 1.05189e-01, 1.22196e-01, 1.05440e-01, 8.15370e-02,\n",
       "        5.98130e-02, 5.01510e-02, 3.71050e-02, 2.75140e-02, 1.69290e-02,\n",
       "        3.03910e-02, 1.57780e-02],\n",
       "       [2.26750e-02, 4.20080e-02, 4.34380e-02, 9.74700e-02, 9.75770e-02,\n",
       "        1.17864e-01, 1.17196e-01, 1.13002e-01, 1.00660e-01, 7.45840e-02,\n",
       "        5.60970e-02, 4.09080e-02, 3.33590e-02, 1.52080e-02, 9.05500e-03,\n",
       "        1.45030e-02, 4.39500e-03]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_1[111]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "571e015b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14113, 102)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_1 = matrix_1.reshape(14113,-1)\n",
    "matrix_1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da03d5cb",
   "metadata": {},
   "source": [
    "# Converting the data into pytorch tenors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70a724b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([14113, 102]), torch.Size([14113, 1]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = torch.from_numpy(matrix_1)\n",
    "targets = torch.from_numpy(target_pagerank)\n",
    "features.shape, targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3cf09de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9985],\n",
       "        [0.8875],\n",
       "        [0.5463],\n",
       "        ...,\n",
       "        [0.2811],\n",
       "        [0.4245],\n",
       "        [0.3886]], dtype=torch.float64, requires_grad=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Activating the automatic gradient \n",
    "features.requires_grad_(True)\n",
    "targets.requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ab8749e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10000, 102]),\n",
       " torch.Size([4113, 102]),\n",
       " torch.Size([10000, 1]),\n",
       " torch.Size([4113, 1]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shuffling and dividing the indecies\n",
    "n_samples = features.shape[0]\n",
    "n_test = 4113\n",
    "shuffled_ind = torch.randperm(n_samples)\n",
    "train_ind = shuffled_ind[:-n_test]\n",
    "test_ind = shuffled_ind[-n_test:]\n",
    "# Dividing features and targets into tain and test sets\n",
    "train_features = features[train_ind]\n",
    "test_features = features[test_ind]\n",
    "train_targets = targets[train_ind]\n",
    "test_targets = targets[test_ind]\n",
    "train_features.shape, test_features.shape, train_targets.shape, test_targets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d960fdc",
   "metadata": {},
   "source": [
    "## A function for dividing train data into batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0515de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dividing train_features and train_targets into batches\n",
    "def next_batch(train_features, train_targets, batch_size=100):\n",
    "    num_features = train_features.shape[0]\n",
    "    # Shuffling\n",
    "    shuffled_ind = torch.randperm(num_features)\n",
    "    shuffled_train_features = train_features[shuffled_ind]\n",
    "    shuffled_train_targets = train_targets[shuffled_ind]\n",
    "    # Dividing\n",
    "    i = 0\n",
    "    while i < num_features:\n",
    "        i += batch_size\n",
    "        yield (shuffled_train_features[i-batch_size:i], shuffled_train_targets[i-batch_size:i])\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53422f6",
   "metadata": {},
   "source": [
    "## The feedforward neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8ef9f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Feedforward Neural Network \n",
    "class FFNN_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        num_features = features.shape[1]\n",
    "        self.fc1 = nn.Linear(num_features, 400)\n",
    "        self.fc2 = nn.Linear(400, 800)\n",
    "        self.fc3 = nn.Linear(800, 200)\n",
    "        self.fc4 = nn.Linear(200, 64)\n",
    "        self.fc5 = nn.Linear(64, 8)\n",
    "        self.fc6 = nn.Linear(8, 1)\n",
    "        self.dropout1 = nn.Dropout(0.4)\n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "        self.dropout3 = nn.Dropout(0.5)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        X = torch.tanh(self.fc1(X))\n",
    "        X = torch.relu(self.fc2(X))\n",
    "        X = self.dropout1(X)\n",
    "        X = torch.relu(self.fc3(X))\n",
    "        X = self.dropout3(X)\n",
    "        X = torch.relu(self.fc4(X))\n",
    "        X = self.dropout2(X)\n",
    "        X = torch.tanh(self.fc5(X))\n",
    "        return self.fc6(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dbd6afbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FFNN_model(\n",
       "  (fc1): Linear(in_features=102, out_features=400, bias=True)\n",
       "  (fc2): Linear(in_features=400, out_features=800, bias=True)\n",
       "  (fc3): Linear(in_features=800, out_features=200, bias=True)\n",
       "  (fc4): Linear(in_features=200, out_features=64, bias=True)\n",
       "  (fc5): Linear(in_features=64, out_features=8, bias=True)\n",
       "  (fc6): Linear(in_features=8, out_features=1, bias=True)\n",
       "  (dropout1): Dropout(p=0.4, inplace=False)\n",
       "  (dropout2): Dropout(p=0.3, inplace=False)\n",
       "  (dropout3): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiation of the model\n",
    "torch.manual_seed(42)\n",
    "model = FFNN_model()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a867c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40800\n",
      "400\n",
      "320000\n",
      "800\n",
      "160000\n",
      "200\n",
      "12800\n",
      "64\n",
      "512\n",
      "8\n",
      "8\n",
      "1\n",
      "----------------------\n",
      "Number of all parameters: \n",
      "535593\n"
     ]
    }
   ],
   "source": [
    "# Number of parameters\n",
    "num_para = 0\n",
    "for param in model.parameters():\n",
    "    print(param.numel())\n",
    "    num_para += param.numel()\n",
    "print(\"----------------------\")\n",
    "print(f'Number of all parameters: \\n{num_para}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f68fb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objective function and optimmizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d430bc",
   "metadata": {},
   "source": [
    "## Defining the Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c9b4697",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs=1000,\n",
    "                  batch_size=100,\n",
    "                  optimizer=optimizer, \n",
    "                  model=model, \n",
    "                  loss_fn=criterion, \n",
    "                  train_features=train_features, \n",
    "                  test_features=test_features, \n",
    "                  train_targets=train_targets, \n",
    "                  test_targets=test_targets):\n",
    "    num_features = train_features.shape[0]\n",
    "    start_time = time.time()\n",
    "    all_train_loss, all_test_loss = np.zeros(n_epochs), np.zeros(n_epochs)\n",
    "    for epoch in range(1, n_epochs +1):\n",
    "        # Training: \n",
    "        epoch_losses = []\n",
    "        # looping through batches\n",
    "        for train_features, train_targets in next_batch(train_features=train_features, \n",
    "                                                        train_targets=train_targets, batch_size=batch_size): \n",
    "            train_preds = model(train_features.float())\n",
    "            train_loss = loss_fn(train_targets.float(), train_preds.float())\n",
    "            optimizer.zero_grad()\n",
    "            train_loss.backward(retain_graph=True)\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_losses.append(train_loss.item())\n",
    "        average_epoch_loss = sum(epoch_losses)/len(epoch_losses)\n",
    "        \n",
    "        # Test:\n",
    "        with torch.no_grad():\n",
    "            test_preds = model(test_features.float())\n",
    "            test_loss = loss_fn(test_targets.float(), test_preds.float())\n",
    "        \n",
    "        all_train_loss[epoch - 1] = average_epoch_loss\n",
    "        all_test_loss[epoch - 1] = test_loss.item()\n",
    "        # Printing the result: \n",
    "        if epoch == 1 or epoch % 100 == 0:\n",
    "            print(f\"EPOCH: {epoch:{7}}\")\n",
    "            print(f\"MEAN TRAIN LOSS:   {average_epoch_loss:.11f},    TEST LOSS:   {test_loss.item():.11f}\")\n",
    "            print(\"-----------------------------------------\")\n",
    "    print(\"The total time = \", np.round(time.time() - start_time, 3), \" seconds!\")\n",
    "    return all_train_loss, all_test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ab2601",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0a9afbe6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH:       1\n",
      "MEAN TRAIN LOSS:   0.59550533772,    TEST LOSS:   0.38120040298\n",
      "-----------------------------------------\n",
      "EPOCH:     100\n",
      "MEAN TRAIN LOSS:   0.13108579814,    TEST LOSS:   0.23530314863\n",
      "-----------------------------------------\n",
      "EPOCH:     200\n",
      "MEAN TRAIN LOSS:   0.08588232100,    TEST LOSS:   0.18210597336\n",
      "-----------------------------------------\n",
      "EPOCH:     300\n",
      "MEAN TRAIN LOSS:   0.06122250855,    TEST LOSS:   0.15086689591\n",
      "-----------------------------------------\n",
      "EPOCH:     400\n",
      "MEAN TRAIN LOSS:   0.04752271622,    TEST LOSS:   0.12933504581\n",
      "-----------------------------------------\n",
      "EPOCH:     500\n",
      "MEAN TRAIN LOSS:   0.03800502419,    TEST LOSS:   0.11186837405\n",
      "-----------------------------------------\n",
      "EPOCH:     600\n",
      "MEAN TRAIN LOSS:   0.03134804219,    TEST LOSS:   0.10377064347\n",
      "-----------------------------------------\n",
      "EPOCH:     700\n",
      "MEAN TRAIN LOSS:   0.02602658980,    TEST LOSS:   0.09303259104\n",
      "-----------------------------------------\n",
      "EPOCH:     800\n",
      "MEAN TRAIN LOSS:   0.02088272013,    TEST LOSS:   0.08542239666\n",
      "-----------------------------------------\n",
      "EPOCH:     900\n",
      "MEAN TRAIN LOSS:   0.01824139059,    TEST LOSS:   0.08198675513\n",
      "-----------------------------------------\n",
      "EPOCH:    1000\n",
      "MEAN TRAIN LOSS:   0.01674983464,    TEST LOSS:   0.07646007091\n",
      "-----------------------------------------\n",
      "EPOCH:    1100\n",
      "MEAN TRAIN LOSS:   0.01503203250,    TEST LOSS:   0.07424262166\n",
      "-----------------------------------------\n",
      "EPOCH:    1200\n",
      "MEAN TRAIN LOSS:   0.01412552688,    TEST LOSS:   0.07611575723\n",
      "-----------------------------------------\n",
      "EPOCH:    1300\n",
      "MEAN TRAIN LOSS:   0.01300976425,    TEST LOSS:   0.06722091138\n",
      "-----------------------------------------\n",
      "EPOCH:    1400\n",
      "MEAN TRAIN LOSS:   0.01092027407,    TEST LOSS:   0.06679263711\n",
      "-----------------------------------------\n",
      "EPOCH:    1500\n",
      "MEAN TRAIN LOSS:   0.01025256794,    TEST LOSS:   0.06876477599\n",
      "-----------------------------------------\n",
      "The total time =  366.98  seconds!\n"
     ]
    }
   ],
   "source": [
    "losses = training_loop(n_epochs=1500,\n",
    "                  batch_size=400,\n",
    "                  optimizer=optimizer, \n",
    "                  model=model, \n",
    "                  loss_fn=criterion, \n",
    "                  train_features=train_features, \n",
    "                  test_features=test_features, \n",
    "                  train_targets=train_targets, \n",
    "                  test_targets=test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "236809d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target 0.653368948866709,    prediction: 0.622930109500885\n",
      "index 0:       inaccuracy: 4.659%\n",
      "-----------------------------------------------------------------\n",
      "target 0.4166771078709456,    prediction: 0.4043075442314148\n",
      "index 100:       inaccuracy: 2.969%\n",
      "-----------------------------------------------------------------\n",
      "target 0.5334529358343941,    prediction: 0.5329790711402893\n",
      "index 200:       inaccuracy: 0.089%\n",
      "-----------------------------------------------------------------\n",
      "target 0.37361047472381503,    prediction: 0.35124707221984863\n",
      "index 300:       inaccuracy: 5.986%\n",
      "-----------------------------------------------------------------\n",
      "target 3.4204442682625955,    prediction: 3.470186710357666\n",
      "index 400:       inaccuracy: 1.454%\n",
      "-----------------------------------------------------------------\n",
      "target 0.7790568506764711,    prediction: 0.6684806942939758\n",
      "index 500:       inaccuracy: 14.194%\n",
      "-----------------------------------------------------------------\n",
      "target 0.5358195165968687,    prediction: 0.5404996871948242\n",
      "index 600:       inaccuracy: 0.873%\n",
      "-----------------------------------------------------------------\n",
      "target 0.6930149689416492,    prediction: 0.8098519444465637\n",
      "index 700:       inaccuracy: 16.859%\n",
      "-----------------------------------------------------------------\n",
      "target 0.36253033082773345,    prediction: 0.34943410754203796\n",
      "index 800:       inaccuracy: 3.612%\n",
      "-----------------------------------------------------------------\n",
      "target 3.7202255654825493,    prediction: 3.5880608558654785\n",
      "index 900:       inaccuracy: 3.553%\n",
      "-----------------------------------------------------------------\n",
      "target 0.886761792766905,    prediction: 0.7774494886398315\n",
      "index 1000:       inaccuracy: 12.327%\n",
      "-----------------------------------------------------------------\n",
      "target 1.1081028067666099,    prediction: 1.038434386253357\n",
      "index 1100:       inaccuracy: 6.287%\n",
      "-----------------------------------------------------------------\n",
      "target 0.9388538886482892,    prediction: 0.8311977386474609\n",
      "index 1200:       inaccuracy: 11.467%\n",
      "-----------------------------------------------------------------\n",
      "target 0.29119990182665967,    prediction: 0.30831801891326904\n",
      "index 1300:       inaccuracy: 5.878%\n",
      "-----------------------------------------------------------------\n",
      "target 0.7249872991123569,    prediction: 0.725904107093811\n",
      "index 1400:       inaccuracy: 0.126%\n",
      "-----------------------------------------------------------------\n",
      "target 0.2859391429845675,    prediction: 0.2854648530483246\n",
      "index 1500:       inaccuracy: 0.166%\n",
      "-----------------------------------------------------------------\n",
      "target 0.20453682360899383,    prediction: 0.2159314602613449\n",
      "index 1600:       inaccuracy: 5.571%\n",
      "-----------------------------------------------------------------\n",
      "target 1.2220035835106888,    prediction: 1.2186065912246704\n",
      "index 1700:       inaccuracy: 0.278%\n",
      "-----------------------------------------------------------------\n",
      "target 1.2162175667545865,    prediction: 1.199920415878296\n",
      "index 1800:       inaccuracy: 1.34%\n",
      "-----------------------------------------------------------------\n",
      "target 0.23134755297638074,    prediction: 0.22847039997577667\n",
      "index 1900:       inaccuracy: 1.244%\n",
      "-----------------------------------------------------------------\n",
      "target 0.4939433952209337,    prediction: 0.4480266571044922\n",
      "index 2000:       inaccuracy: 9.296%\n",
      "-----------------------------------------------------------------\n",
      "target 0.6879245371525278,    prediction: 0.757306694984436\n",
      "index 2100:       inaccuracy: 10.086%\n",
      "-----------------------------------------------------------------\n",
      "target 1.8397944931109307,    prediction: 1.7847601175308228\n",
      "index 2200:       inaccuracy: 2.991%\n",
      "-----------------------------------------------------------------\n",
      "target 0.5934998172649127,    prediction: 0.5292984843254089\n",
      "index 2300:       inaccuracy: 10.817%\n",
      "-----------------------------------------------------------------\n",
      "target 1.0252243047092422,    prediction: 0.8447524309158325\n",
      "index 2400:       inaccuracy: 17.603%\n",
      "-----------------------------------------------------------------\n",
      "target 1.3224707501677089,    prediction: 1.2794979810714722\n",
      "index 2500:       inaccuracy: 3.249%\n",
      "-----------------------------------------------------------------\n",
      "target 0.37900862790157824,    prediction: 0.38304245471954346\n",
      "index 2600:       inaccuracy: 1.064%\n",
      "-----------------------------------------------------------------\n",
      "target 0.4888664773107004,    prediction: 0.5478852987289429\n",
      "index 2700:       inaccuracy: 12.073%\n",
      "-----------------------------------------------------------------\n",
      "target 0.44864792453447777,    prediction: 0.4478854238986969\n",
      "index 2800:       inaccuracy: 0.17%\n",
      "-----------------------------------------------------------------\n",
      "target 0.9598222644012611,    prediction: 0.8042100071907043\n",
      "index 2900:       inaccuracy: 16.213%\n",
      "-----------------------------------------------------------------\n",
      "target 0.2597719178888111,    prediction: 0.26894524693489075\n",
      "index 3000:       inaccuracy: 3.531%\n",
      "-----------------------------------------------------------------\n",
      "target 0.21056114189988248,    prediction: 0.219094917178154\n",
      "index 3100:       inaccuracy: 4.053%\n",
      "-----------------------------------------------------------------\n",
      "target 1.0567964462315458,    prediction: 1.035287618637085\n",
      "index 3200:       inaccuracy: 2.035%\n",
      "-----------------------------------------------------------------\n",
      "target 0.4981315394602801,    prediction: 0.5763119459152222\n",
      "index 3300:       inaccuracy: 15.695%\n",
      "-----------------------------------------------------------------\n",
      "target 0.6616910455247774,    prediction: 0.6341962814331055\n",
      "index 3400:       inaccuracy: 4.155%\n",
      "-----------------------------------------------------------------\n",
      "target 0.5253577999936322,    prediction: 0.5936340093612671\n",
      "index 3500:       inaccuracy: 12.996%\n",
      "-----------------------------------------------------------------\n",
      "target 0.47193069583165626,    prediction: 0.463841050863266\n",
      "index 3600:       inaccuracy: 1.714%\n",
      "-----------------------------------------------------------------\n",
      "target 0.26016805454065767,    prediction: 0.24053658545017242\n",
      "index 3700:       inaccuracy: 7.546%\n",
      "-----------------------------------------------------------------\n",
      "target 0.4340501551534385,    prediction: 0.43076664209365845\n",
      "index 3800:       inaccuracy: 0.756%\n",
      "-----------------------------------------------------------------\n",
      "target 1.4039715764597291,    prediction: 1.3156514167785645\n",
      "index 3900:       inaccuracy: 6.291%\n",
      "-----------------------------------------------------------------\n",
      "target 1.501312518537096,    prediction: 1.2883025407791138\n",
      "index 4000:       inaccuracy: 14.188%\n",
      "-----------------------------------------------------------------\n",
      "target 0.8429847076437201,    prediction: 0.7285248637199402\n",
      "index 4100:       inaccuracy: 13.578%\n",
      "-----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "errors = []\n",
    "for i in range(n_test):\n",
    "    targ = test_targets[i].item()\n",
    "    feat = test_features[i].float().view(1,1,102)\n",
    "    pred = model(feat).item()\n",
    "    inaccuracy = abs(1 - pred/targ) * 100\n",
    "    errors.append(inaccuracy)\n",
    "    if i%100 == 0:\n",
    "        print(f\"target {targ},    prediction: {pred}\\nindex {i}:       inaccuracy: {np.round(inaccuracy, 3)}%\")\n",
    "        print(\"-----------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0a813b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average inaccuracy:  8.069\n"
     ]
    }
   ],
   "source": [
    "print(\"Average inaccuracy: \", np.round(sum(errors)/len(errors), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4f7a0d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"trained_FFNN_model_pagerank_discounted_1500epochs.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3225f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
